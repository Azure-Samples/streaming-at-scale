{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "input_table_location = '/datalake/normalized/streaming_device'\r\n",
        "test_output_path = '/test-ouptut/verify-delta/output.txt'\r\n",
        "assert_events_per_second = 900\r\n",
        "assert_latency_milliseconds = 15000\r\n",
        "assert_duplicate_fraction = 0\r\n",
        "assert_out_of_sequence_fraction = 0"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 23,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:45.7588738Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:46.0269856Z",
              "execution_finish_time": "2022-06-10T18:14:46.027275Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 23, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql import Window"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 24,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:45.8157395Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:46.1401132Z",
              "execution_finish_time": "2022-06-10T18:14:46.2825528Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 24, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = spark.read.format('delta').load(input_table_location).cache()\r\n",
        "assertions_failed = []"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:45.8862038Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:46.4162162Z",
              "execution_finish_time": "2022-06-10T18:14:46.9269296Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 25, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "stored_by_minute_stats = input_data.withColumn(\"storedAtMinute\", (floor(unix_timestamp(col('storedAt')) / 60) * 60).cast(\"timestamp\")) \\\r\n",
        "    .withColumn(\"latency\", col('storedAt').cast(\"double\") - col('enqueuedAt').cast(\"double\")) \\\r\n",
        "    .groupBy(col('storedAtMinute')) \\\r\n",
        "    .agg(\r\n",
        "      (count(col('eventId'))/lit(60)).alias(\"events_per_second\"),\r\n",
        "      avg(col('latency')).alias(\"avg_latency_s\")\r\n",
        "    ) \\\r\n",
        "    .orderBy(col('storedAtMinute')) \\\r\n",
        "    .cache()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:45.9868979Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:47.0638691Z",
              "execution_finish_time": "2022-06-10T18:14:47.2347311Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 26, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stored_stats = stored_by_minute_stats.agg(\r\n",
        "  count(col('storedAtMinute')).alias(\"minutesWithData\"),\r\n",
        "  max(col('events_per_second')).alias(\"maxThroughputEventsPerSecond\"),\r\n",
        "  min(col('avg_latency_s')).alias(\"minLatencySeconds\")\r\n",
        ").cache()\r\n",
        "\r\n",
        "stored_stats_row = stored_stats.collect()[0]\r\n",
        "max_throughput_events_per_second = stored_stats_row['maxThroughputEventsPerSecond']\r\n",
        "min_latency_seconds = stored_stats_row['minLatencySeconds']\r\n",
        "\r\n",
        "if assert_events_per_second and assert_events_per_second >= 0:\r\n",
        "  expected = assert_events_per_second\r\n",
        "  actual = max_throughput_events_per_second\r\n",
        "  if (actual or (actual < expected)):\r\n",
        "    assertions_failed.append(f\"min throughput per second: expected min {expected}, got {actual}\")\r\n",
        "\r\n",
        "if assert_latency_milliseconds and assert_latency_milliseconds >= 0:\r\n",
        "  expected = assert_latency_milliseconds\r\n",
        "  actual = min_latency_seconds\r\n",
        "  if (actual or ((actual * 1000) > expected)):\r\n",
        "    assertions_failed.append(f\"max latency in milliseconds: expected max {expected} milliseconds, got {actual} seconds\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 27,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:46.1114655Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:47.3705847Z",
              "execution_finish_time": "2022-06-10T18:14:47.5163427Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 27, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = input_data \\\r\n",
        "    .groupBy(col('eventId')) \\\r\n",
        "    .agg(count(col('eventId')).alias(\"count\")) \\\r\n",
        "    .where(col('count') > 1) \\\r\n",
        "    .count()\r\n",
        "\r\n",
        "duplicate_fraction = float(duplicates)/float(input_data.count())\r\n",
        "\r\n",
        "if assert_duplicate_fraction and assert_duplicate_fraction >= 0:\r\n",
        "  expected = assert_duplicate_fraction\r\n",
        "  if duplicate_fraction > expected:\r\n",
        "    assertions_failed.append(f\"fraction of duplicate events: expected max {expected}, got {duplicate_fraction}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 28,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:46.198563Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:14:47.6223851Z",
              "execution_finish_time": "2022-06-10T18:16:02.5184833Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 28, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_sequence = Window.partitionBy(\"deviceId\").orderBy(col('storedAt'), col('deviceSequenceNumber'))\r\n",
        "\r\n",
        "out_of_sequence = input_data \\\r\n",
        "  .withColumn(\"deviceSequenceNumberDelta\", col('deviceSequenceNumber') - lag(col('deviceSequenceNumber'), 1).over(time_sequence)) \\\r\n",
        "  .filter(col('deviceSequenceNumberDelta') > 1) \\\r\n",
        "  .count()\r\n",
        "\r\n",
        "out_of_sequence_fraction = float(out_of_sequence) / float(input_data.count())\r\n",
        "\r\n",
        "if assert_out_of_sequence_fraction and assert_out_of_sequence_fraction >= 0:\r\n",
        "  expected = assert_outofsequence_fraction\r\n",
        "  if (out_of_sequence_fraction > expected):\r\n",
        "    assertionsFailed.append(f\"fraction of out-of-sequence events: expected max {expected}, got {out_of_sequence_fraction}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 29,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:46.3857055Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:16:02.7822714Z",
              "execution_finish_time": "2022-06-10T18:16:56.5954849Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 29, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_sequence = Window.partitionBy(\"deviceId\").orderBy(col('deviceSequenceNumber'))\r\n",
        "device_partition = Window.partitionBy(\"deviceId\")\r\n",
        "\r\n",
        "missing_events = input_data \\\r\n",
        "  .withColumn(\"orderInDevice\", row_number().over(device_sequence)) \\\r\n",
        "  .withColumn(\"countForDevice\", count(\"*\").over(device_partition)) \\\r\n",
        "  .withColumn(\"fractionInOrder\", col('orderInDevice').cast(\"double\") / col('countForDevice')) \\\r\n",
        "  .filter((col('fractionInOrder') >= lit(0.1)) & (col('fractionInOrder') <= lit(0.9))) \\\r\n",
        "  .withColumn(\"deviceSequenceNumberDelta\", col('deviceSequenceNumber') - lag(col('deviceSequenceNumber'), 1).over(device_sequence)) \\\r\n",
        "  .filter(col('deviceSequenceNumberDelta') > lit(1)) \\\r\n",
        "  .count()\r\n",
        "\r\n",
        "missing_fraction = float(missing_events) / float(input_data.count())\r\n",
        "\r\n",
        "assert_missing_fraction = 0.0\r\n",
        "expected = assert_missing_fraction\r\n",
        "if (missing_fraction > expected):\r\n",
        "    assertionsFailed.append(f\"fraction of missing events: expected max {expected}, got {missing_fraction}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 30,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:14:46.6047848Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:16:56.7287797Z",
              "execution_finish_time": "2022-06-10T18:18:07.2129205Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 30, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assertions_failed_str = '\\n'.join(assertions_failed)\r\n",
        "mssparkutils.fs.put(test_output_path, assertions_failed_str, True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sasesssparkpool",
              "session_id": 454,
              "statement_id": 33,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-10T18:46:24.1038821Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-10T18:46:24.2105913Z",
              "execution_finish_time": "2022-06-10T18:46:24.7283182Z"
            },
            "text/plain": "StatementMeta(sasesssparkpool, 454, 33, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}