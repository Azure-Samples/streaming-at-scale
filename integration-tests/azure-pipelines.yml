trigger:
- master

jobs:

- job: start_agent
  steps:
  - task: AzureCLI@1
    inputs:
      azureSubscription: ARMConnection
      scriptLocation: 'inlineScript'
      inlineScript: az vm start -g "$AGENT_VM_RESOURCE_GROUP" -n "$AGENT_VM_NAME"
    displayName: 'start agent'

- job: run_tests
  dependsOn: start_agent
  timeoutInMinutes: 0
  pool:
    name: streaming-at-scale
  variables:
    DATABRICKS_HOST: https://$(LOCATION).azuredatabricks.net
  steps:

  - bash: |
      set -e
      sudo apt install -y python3-pip python3-setuptools
      sudo pip3 install wheel databricks-cli
      databricks clusters spark-versions
      echo "##vso[task.setVariable variable=DATABRICKS_TOKEN]$DATABRICKS_TOKEN"
    displayName: Install Databricks CLI and expose token to next tasks
    env:
      DATABRICKS_TOKEN: $(DATABRICKS_PAT_TOKEN)

  - script: |
      pip3 install pytest pytest-azurepipelines flaky
    displayName: 'Install test dependencies'

  - task: AzureCLI@1
    inputs:
      azureSubscription: ARMConnection
      scriptLocation: 'inlineScript'
      inlineScript: cd integration-tests && python3 -m pytest -s --stage 1
    displayName: 'pytest stage 1'

  - task: AzureCLI@1
    inputs:
      azureSubscription: ARMConnection
      scriptLocation: 'inlineScript'
      inlineScript: cd integration-tests && python3 -m pytest -s --stage 2
    displayName: 'pytest stage 2'

  - task: AzureCLI@1
    inputs:
      azureSubscription: ARMConnection
      scriptLocation: 'inlineScript'
      inlineScript: cd integration-tests && python3 -m pytest -s --stage 3
      # Provide service principal (for Azure Data Explorer RBAC setup)
      addSpnToEnvironment: true
    displayName: 'pytest stage 3'
